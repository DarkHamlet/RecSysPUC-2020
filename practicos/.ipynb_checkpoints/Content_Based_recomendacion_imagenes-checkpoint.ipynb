{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONpCTNsBRT5E"
   },
   "source": [
    "# Tutorial VisRank\n",
    "\n",
    "\n",
    "\n",
    "Profesor: Denis Parra\n",
    "\n",
    "Ayudantes: Vladimir Araujo, Andrés Carvallo, Manuel Cartagena, Francisca Catan, Andres Villa \n",
    "\n",
    "Agradecimientos al gran: Pablo Messina\n",
    "\n",
    "En este proyecto trabajaremos con un modelo de [recomendación de arte](http://dparra.sitios.ing.uc.cl/pdfs/preprint-ugallery-UMUAI-2018.pdf). El modelo de recomendación de arte es un modelo basado en contenido, donde se utilizan redes neuronales convolucionales para el cálculo de similaridades de ítems. Luego, dependiendo de los productos que el usuario ha consumido, se recomiendan los ítems más similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNTQW1UnRT5H"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import heapq\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Y0gmJtnRiFK"
   },
   "outputs": [],
   "source": [
    "!curl -L -o \"assets.tar.gz\" \"https://drive.google.com/uc?export=download&id=1PDvB7at0AmDSXFFcXe9nO6k2QbbJpzqY\"\n",
    "!tar -xvzf assets.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNI10gKgRT5Q"
   },
   "source": [
    "# Cargar caracteristicas visuales pre-entrenadas: Redes ResNet50 and VGG19\n",
    "\n",
    "En esta sección se trabajará con modelos pre-entrenados de redes convolucionales (CNN) que extraen caracteristicas visuales de las imagenes. Usaremos las arquitecturas ResNet50 y VGG19\n",
    "\n",
    "![Ejemplo de red convolucional](http://dparra.sitios.ing.uc.cl/img/alexnet-ugallery.png)\n",
    "\n",
    "\n",
    "\n",
    "Para los curiosos se recomienda revisar los siguientes links:\n",
    "\n",
    "- Artículo: [Understand Deep Residual Networks](https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624)\n",
    "- [Keras applications](https://keras.io/applications/)\n",
    "\n",
    "Para efectos de este trabajo los vectores de características ya fueron entrenados y guardados en archivos numpy. A continuación son cargados en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7EWnNDvRT5T"
   },
   "outputs": [],
   "source": [
    "resnet50_featmat = np.load('./assets/resnet50_feature_matrix.npy', allow_pickle=True)\n",
    "vgg19_featmat = np.load('./assets/vgg19_feature_matrix.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8kxstYYRT5Z"
   },
   "source": [
    "### **Pregunta 1** \n",
    "\n",
    "Considerando que haremos un recomendador basado en contenidos ¿Por qué el uso de estas redes (CNN) es una buena elección para este tipo de problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4l-XSPZRT5b"
   },
   "source": [
    "**Respuesta 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oX6CanepmxpG"
   },
   "source": [
    "### Pregunta 2\n",
    "\n",
    "Considerando que para este problema las pinturas son únicas, ¿Sirve utilizar modelos antes vistos de filtrado colaborativo (UserKNN, ItemKNN, etc) ? Justifique con los contenidos vistos del curso esta respuesta. Del mismo modo, ¿sirve utilizar Most Popular? ¿Por qué?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8TevKarnVr_"
   },
   "source": [
    "**Respuesta 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJJJSSCzRT5d"
   },
   "source": [
    "# Cargar archivos adicionales json\n",
    "\n",
    "En esta sección se cargan archivos auxiliares que luego serán útiles para el cálculo de las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrPFAHljRT5e"
   },
   "outputs": [],
   "source": [
    "print('Loading index2artworkId.json')\n",
    "with open('./assets/index2artworkId.json') as f:\n",
    "    index2id = json.load(f)\n",
    "    id2index = {_id:i for i,_id in enumerate(index2id)}\n",
    "    \n",
    "print('Loading past_transactions.pickle')\n",
    "with open('./assets/past_transactions.pickle', 'rb') as f:\n",
    "    past_transactions = pickle.load(f)\n",
    "    \n",
    "print('Loading ground_truth.pickle')\n",
    "with open('./assets/ground_truth.pickle', 'rb') as f:\n",
    "    ground_truth = pickle.load(f)\n",
    "    \n",
    "print(\"-------------\")\n",
    "print(\"Cantidad de usuarios distintos: \", len(index2id))\n",
    "print(\"Cantidad de features en ResNET50: \", resnet50_featmat.shape[1])\n",
    "print(\"Cantidad de features en VGG19: \", vgg19_featmat.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q9erL-R9RT5k"
   },
   "source": [
    "# Concatenar  ResNet50 + VGG19, aplicar normalización z-score normalization y finalmente PCA(20)\n",
    "\n",
    "Una vez calculado (o cargado) los vectores característicos de cada imagen, se deben preprocesar para generar un único vector por cada instancia. Para lograr este objetivo se concatenan los vectores de las redes ResNet50 y VGG19, luego son normalizados restando la media del vector a cada dimensión y luego dividir por su desviación estándar.\n",
    "\n",
    "$x_i = \\frac{x_i - \\bar{x}}{\\sigma}$\n",
    "\n",
    "Finalmente los vectores son reducidos a una dimensión de 20 mediante el algoritmo PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kk2rRw2KRT5m"
   },
   "outputs": [],
   "source": [
    "def normalize_zscore_inplace(featmat):\n",
    "    means = featmat.mean(0)\n",
    "    stds = featmat.std(0)\n",
    "    for i in range(stds.shape[0]):\n",
    "        if stds[i] == 0:\n",
    "            stds[i] = 1\n",
    "    featmat -= means\n",
    "    featmat /= stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTlCIMPMRT5s"
   },
   "outputs": [],
   "source": [
    "n_artworks = len(index2id)\n",
    "resnet50_dim = resnet50_featmat.shape[1]\n",
    "vgg19_dim = vgg19_featmat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xVW-G78RT5y"
   },
   "outputs": [],
   "source": [
    "resnet_vgg_hybrid_featmat = np.empty(shape=(n_artworks, resnet50_dim + vgg19_dim))\n",
    "for i in range(n_artworks):\n",
    "    resnet_vgg_hybrid_featmat[i][:resnet50_dim] = resnet50_featmat[i]\n",
    "    resnet_vgg_hybrid_featmat[i][resnet50_dim:] = vgg19_featmat[i]\n",
    "normalize_zscore_inplace(resnet_vgg_hybrid_featmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEYmmlisRT55"
   },
   "outputs": [],
   "source": [
    "# Project into a 20 PCA feature space\n",
    "pca20_resnet_vgg_hybrid_featmat = PCA(n_components=20).fit_transform(resnet_vgg_hybrid_featmat)\n",
    "\n",
    "print(\"Cantidad de features despues de PCA: \", pca20_resnet_vgg_hybrid_featmat.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ii1crr2-RT5-"
   },
   "source": [
    "## **Pregunta 3**\n",
    "\n",
    "Comente por qué se utiliza PCA para reducir la dimensión de cada vector característico. ¿Qué sucede con la pérdida de información en la reducción de dimensionalidad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6bib3SzRT6A"
   },
   "source": [
    "**Respuesta 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6khDyXoRT6B"
   },
   "source": [
    "# Similar image retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEHe5PopRT6E"
   },
   "source": [
    "En esta sección utilizaremos los vectores cargados para hacer un sistema de recuperación o búsqueda de información, para diferentes métricas de distancia. El siguiente código es una clase utiliza de forma **interna** (no editar) para manejar las imágenes que verán despues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2H8ZOAbRT6G"
   },
   "outputs": [],
   "source": [
    "class _ImageHandler:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._IMAGE_URLS = None\n",
    "        self._IMAGES_CACHE = dict()\n",
    "\n",
    "    def _load_image_urls(self):\n",
    "        if self._IMAGE_URLS is None:\n",
    "            with open('./assets/artworkImageUrlsCache.json') as f:\n",
    "                self._IMAGE_URLS = json.load(f)\n",
    "    \n",
    "    def _download_image(self, _id):\n",
    "        url = self._IMAGE_URLS[str(_id)]['medium']\n",
    "        try:\n",
    "            r = requests.get(url, timeout=4)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print('timeout detected for url = ', url)\n",
    "            return False\n",
    "        if r.status_code == 200:\n",
    "            img = Image.open(BytesIO(r.content))\n",
    "            self._IMAGES_CACHE[_id] = img\n",
    "            return True\n",
    "        else:\n",
    "            print('unexpected r.status_code = %d for url = %s' % (r.status_code, url))\n",
    "            return False\n",
    "    \n",
    "    def download_images(self, ids):\n",
    "        missing_ids = [_id for _id in ids if _id not in self._IMAGES_CACHE]\n",
    "        if len(missing_ids) == 0:\n",
    "            return        \n",
    "        self._load_image_urls()\n",
    "        from concurrent.futures import ThreadPoolExecutor\n",
    "        with ThreadPoolExecutor(max_workers=30) as executor:\n",
    "            executor.map(self._download_image, missing_ids)\n",
    "            executor.shutdown(wait=True)    \n",
    "\n",
    "    def get_image(self, _id):\n",
    "        try:\n",
    "            img = self._IMAGES_CACHE[_id]\n",
    "        except KeyError:\n",
    "            self._load_image_urls()\n",
    "            if self._download_image(_id):\n",
    "                img = self._IMAGES_CACHE[_id]\n",
    "            else:\n",
    "                img = None\n",
    "        return img\n",
    "\n",
    "ImageHandler = _ImageHandler() # singleton instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8TkpLKlohZd"
   },
   "source": [
    "La siguiente función es para imprimir las imágenes en pantalla. **(no editar)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_23zW0U7RT6L"
   },
   "outputs": [],
   "source": [
    "def plot_images(ids):    \n",
    "    plt.close()\n",
    "    n = len(ids)\n",
    "    nrows = math.ceil(n/5)\n",
    "    ncols = min(n, 5)\n",
    "    plt.figure(1, (20, 5 * nrows))\n",
    "\n",
    "    ImageHandler.download_images(ids)\n",
    "    for i, _id in enumerate(ids):\n",
    "        ax = plt.subplot(nrows, ncols, i+1)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        img = ImageHandler.get_image(_id)\n",
    "        if img is None:\n",
    "            ax.set_title('%d) id = %d not found' % (i, _id))\n",
    "        else:\n",
    "            ax.set_title('%d) id = %d' % (i, _id))\n",
    "            ax.imshow(img, interpolation=\"nearest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7FRwpNwolfH"
   },
   "source": [
    "La siguiente función busca las `topk` imágenes más cercanas según la métrica de distancia indicada. **no editar**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItVxZz45RT6V"
   },
   "outputs": [],
   "source": [
    "# Find similar images by query id\n",
    "\n",
    "def find_similar_images(embedding, query_id=None, metrics=('euclidean',), topk=5):\n",
    "    assert len(metrics) > 0\n",
    "    assert topk <= 30 # to avoid requesting too many images\n",
    "    n = embedding.shape[0]\n",
    "    if query_id is None:\n",
    "        query_i = np.random.randint(n)\n",
    "        query_id = index2id[query_i]\n",
    "    else:\n",
    "        query_i = id2index[query_id]\n",
    "        \n",
    "    # --- show query image\n",
    "    plt.title('query_id = %d' % query_id)\n",
    "    plt.imshow(ImageHandler.get_image(query_id))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    # --- show retrieved images for each metric\n",
    "    for metric in metrics:\n",
    "        print('-------- retrieved with metric = %s -----' % metric)\n",
    "        distances = pairwise_distances(embedding[query_i].reshape(1,-1), embedding, metric=metric)\n",
    "        heap = []\n",
    "        for i in range(n):            \n",
    "            if len(heap) < topk:\n",
    "                heapq.heappush(heap, (-distances[0][i], i))\n",
    "            else:\n",
    "                heapq.heappushpop(heap, (-distances[0][i], i))\n",
    "        heap.sort(reverse=True)\n",
    "        rec_ids = [index2id[i] for _,i in heap]\n",
    "        plot_images(rec_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KVKsZVPaY2V"
   },
   "source": [
    "**Esta forma de ranking funciona bien para datasets pequeños, para cosas de mayor tamaño pruebe con cosas como [Annoy](https://github.com/spotify/annoy)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vi1Yx1KXRT6e"
   },
   "source": [
    "## Usando ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwuBaA0qRT6g"
   },
   "outputs": [],
   "source": [
    "# Retrieve images using ResNet50\n",
    "find_similar_images(resnet50_featmat, metrics=('cosine','euclidean'), query_id=38858, topk=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qE2LVZkWRT6j"
   },
   "source": [
    "## Usando VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXN8XnjbRT6k"
   },
   "outputs": [],
   "source": [
    "# Retrieve images using VGG19 and cosine similarity\n",
    "find_similar_images(vgg19_featmat, metrics=('cosine','euclidean'), query_id=38858, topk=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1RTrG3sRT6m"
   },
   "source": [
    "## Usando PCA(20) sobre ResNet50+VGG19 hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYTPVQyIRT6o"
   },
   "outputs": [],
   "source": [
    "# Retrieve images using PCA features, cosine and euclidean similarity\n",
    "find_similar_images(pca20_resnet_vgg_hybrid_featmat, metrics=('cosine','euclidean'), query_id=38858, topk=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_A1txE3RT63"
   },
   "source": [
    "# Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9gYBm29RT65"
   },
   "outputs": [],
   "source": [
    "def recommend(embedding, user_id=None, topk=10, metric='cosine'):\n",
    "    if user_id is None:\n",
    "        user_id = np.random.randint(0, 25)\n",
    "    assert user_id >= 0\n",
    "    assert user_id < 25\n",
    "    \n",
    "    print(\"user_id = \", user_id)\n",
    "    \n",
    "    #Calculate distance metrics\n",
    "    trx = past_transactions[user_id]\n",
    "    n = embedding.shape[0]\n",
    "    distances = 1e9\n",
    "        \n",
    "    for t in trx:\n",
    "        query_i = id2index[t]\n",
    "        \n",
    "        # recomendamos items más cercanos a items con los que interactuó el usuario\n",
    "        distances = np.minimum(distances, pairwise_distances(\n",
    "                embedding[query_i].reshape(1,-1), embedding, metric=metric).reshape(-1))\n",
    "\n",
    "    #Rank items \n",
    "    trx_set = set(trx)\n",
    "    heap = []\n",
    "    for i in range(n):\n",
    "        if index2id[i] in trx_set:\n",
    "            continue\n",
    "        if len(heap) < topk:\n",
    "            heapq.heappush(heap, (-distances[i], i))\n",
    "        else:\n",
    "            heapq.heappushpop(heap, (-distances[i], i))\n",
    "    heap.sort(reverse=True)\n",
    "    \n",
    "    # utilizamos un heap para extraer los items ordenados de menor a mayor distancia \n",
    "    recommended_ids = [index2id[i] for _,i in heap]\n",
    "    \n",
    "    #Show consumed items\n",
    "    print('\\t\\t\\t\\t============ Consumed items =============\\n\\n')\n",
    "    plot_images(trx)\n",
    "\n",
    "    #Show recommended items\n",
    "    print('\\n\\n\\n\\t\\t\\t\\t============ Recommended items =============\\n\\n')\n",
    "    plot_images(recommended_ids)\n",
    "    return recommended_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyTqtr9DONsj"
   },
   "source": [
    "El código anterior recomienda para un usuario del siguiente modo:\n",
    "\n",
    "1. Para cada transacción del usuario, se calcula la distancia entre la pintura comprada y todas las demás ítems posibles a recomendar. \n",
    "2. Se busca aquella transacción que tenga la mínima distancia posible a todos los demás ítems\n",
    "3. Se recomienda las pinturas utilizando la distancia de la transacción obtenida en el punto 2. Para esto se van entregando las pinturas que tienen menor distancia a esta. A medida que aumenta la recomiendación, la distancia aumenta. \n",
    "\n",
    "Para el ordenamiento se utilizó el algoritmo [`heapsort`](https://es.wikipedia.org/wiki/Heapsort).\n",
    "\n",
    "## Ejemplos de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6_oT0wpRT6_"
   },
   "outputs": [],
   "source": [
    "#rec = recommend(resnet50_featmat, user_id=8, topk=15)\n",
    "#rec = recommend(vgg19_featmat, user_id=8, topk=15)\n",
    "rec = recommend(pca20_resnet_vgg_hybrid_featmat, user_id=8, topk=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xG7Q6FdrRT7J"
   },
   "source": [
    "## **Pregunta 4** \n",
    "\n",
    "Basado en lo visto en clases indica 2 métricas que midan el rendimiento de nuestro modelo recomendador en este problema. ¿Cuáles son las ventajas y desventajas de cada uno?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aoPuhNWcRT7L"
   },
   "source": [
    "**Respuesta 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "09PllLLmRT7M"
   },
   "source": [
    "## **Pregunta 5** \n",
    "\n",
    "Genera nuevas recomendaciones mediante la función `recommend` cambiando el tipo de _embedding_ y la métrica de distancia para algún usuario. **Importante** puede ser que algunas imágenes ya no estén disponibles, no se asuste por eso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZkbCfx70-uJ-"
   },
   "source": [
    "**Respuesta 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Klem53BaRT7N"
   },
   "outputs": [],
   "source": [
    "# Escribe tu codigo aquí"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial VisRank",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
